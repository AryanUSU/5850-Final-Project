{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32f9a236",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0d671f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of top 25 subreddit names to read files\n",
    "subredditNames = [\"AmItheAsshole\", \"AskReddit\", \"Damnthatsinteresting\", \"DestinyTheGame\", \n",
    "                  \"Home\", \"LivestreamFail\", \"NoStupidQuestions\", \"PublicFreakout\", \"Unexpected\", \n",
    "                  \"WhitePeopleTwitter\", \"antiwork\", \"diablo4\", \"explainlikeimfive\", \"facepalm\", \n",
    "                  \"funny\", \"gaming\", \"interestingasfuck\", \"leagueoflegends\", \"mildlyinfuriating\", \n",
    "                  \"movies\", \"pcmasterrace\", \"pics\", \"therewasanattempt\", \"videos\", \"worldnews\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e65d09c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MisraGries(token, buffer, k): \n",
    "    if token in buffer:\n",
    "        buffer[token] = buffer[token] + 1\n",
    "    elif len(buffer) < k-1:\n",
    "        buffer[token] = 1\n",
    "    else:\n",
    "        keys = list(buffer.keys())\n",
    "        for key in keys:\n",
    "            buffer[key] -= 1\n",
    "            if buffer[key] == 0:\n",
    "                del buffer[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "76e36eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Needs uncommenting if not downloaded\n",
    "# nltk.download('omw-1.4')\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('wordnet')\n",
    "\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "stop = stopwords.words('english')\n",
    "\n",
    "def CommonWord(word):\n",
    "    isCommonWord = False\n",
    "\n",
    "    if len(word) <= 1 or word in stop: isCommonWord = True\n",
    "    elif word.startswith('https://') or word.startswith('http://'): isCommonWord = True\n",
    "\n",
    "    # Performs Lemmatization\n",
    "    word = wordnet_lemmatizer.lemmatize(word)\n",
    "    \n",
    "    return word, isCommonWord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab1e11ae",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AmItheAsshole\n",
      "{'home': 1, 'work': 2, 'job': 1, 'getting': 2, 'school': 1, 'depressed': 1, 'checkup': 1, 'hour': 1, 'kid': 2, 'know': 1, 'silly': 1, 'making': 1, 'fast': 1, 'add': 1, 'get': 1, 'older': 1, 'interferes': 1, 'would': 1, 'feel': 1, 'right': 1, 'bare': 1, 'bloodwork': 1} \n",
      "\n",
      "AskReddit\n",
      "{'bird': 1, 'start': 1, 'societal': 1, 'today': 1, 'level': 1, 'implying': 1, 'sims': 1, 'chain': 1, 'world': 1, 'version': 1, 'higher': 1, 'madden': 1, 'stopped': 1, 'got': 1} \n",
      "\n",
      "Damnthatsinteresting\n",
      "{'sex': 5, 'person': 1, 'attractive': 2, 'know': 1, 'make': 1, 'joke': 1, 'respective': 2, 'attack': 1, 'men': 1, 'one': 1, 'woman': 1, 'recognize': 1, 'think': 1, 'homosexual': 1, 'wtf': 1} \n",
      "\n",
      "DestinyTheGame\n",
      "{'exotic': 3, 'get': 1, 'new': 1, 'look': 1, 'focused': 1, 'hunt': 1, 'ghost': 3, 'anti': 2, 'titan': 1, 'season': 1, 'exclude': 1, 'make': 1, 'mod': 3, 'let': 1, 'remember': 1, 'never': 1, 'perk': 1, 'back': 1, 'slap': 1, 'wish': 1, 'would': 1, 'basically': 1, 'focus': 1} \n",
      "\n",
      "Home\n",
      "{'unscrew': 2, 'life': 1, 'run': 1, 'eel': 1, 'overflow': 1, 'throw': 1, 'sure': 1, 'around': 1, 'there': 1, 'im': 1, 'wizard': 1, 'anything': 1, 'dont': 1, 'metal': 1, 'keep': 1, 'covered': 2, 'rock': 1, 'octagonal': 1, 'maybe': 1, 'smell': 1, 'trap': 1, 'put': 1, 'grill': 1} \n",
      "\n",
      "LivestreamFail\n",
      "{'cat': 10, 'like': 2, 'people': 2, 'french': 1, 'look': 1, 'cute': 2, 'hapsburg': 1, 'find': 1, 'imo': 1, 'grotesque': 1, 'inbred': 1, 'anything': 1, 'yeah': 1, 'abomination': 1} \n",
      "\n",
      "NoStupidQuestions\n",
      "{'love': 13, 'question': 3, 'network': 1, 'ask': 1, 'access': 1, 'wifi': 1, 'common': 1} \n",
      "\n",
      "PublicFreakout\n",
      "{'head': 1, 'bar': 1, 'gotcha': 1, 'bot': 2, 'provided': 4, 'download': 2, 'republic': 1, 'party': 1, 'shame': 1, 'nazi': 1, 'tennessee': 1, 'move': 1, 'america': 1, 'watching': 1, 'something': 1, 'man': 1, 'fascist': 1, 'ass': 1, 'yea': 1, 'dolly': 1} \n",
      "\n",
      "Unexpected\n",
      "{'bot': 1, 'unexpected': 3, 'might': 1, 'pinky': 1, 'either': 1, 'may': 1, 'chocking': 2, 'depends': 1, 'pull': 1, 'hit': 1, 'work': 1, 'backwards': 1, 'crotch': 1, 'also': 1, 'knee': 1, 'front': 1, 'thing': 1, 'almost': 1, 'joke': 2, 'let': 1, 'default': 1, 'expectation': 1, 'subverting': 1, 'original': 1, 'pretentious': 1, 'comedy': 1, 'right': 1, 'reddit': 1, 'sir': 1} \n",
      "\n",
      "WhitePeopleTwitter\n",
      "{'law': 2, 'court': 1, 'gift': 1, 'even': 1, 'supreme': 1, 'people': 1, 'deep': 1, 'office': 1, 'senate': 1, 'fucked': 1, 'removing': 1, 'house': 1, 'yeah': 2, 'posted': 1, 'remove': 1, 'path': 1, 'removal': 1, 'impeach': 1, 'president': 1, 'someone': 1, 'move': 1, 'one': 1, 'post': 1, 'process': 1, 'woof': 1} \n",
      "\n",
      "antiwork\n",
      "{'capitalism': 5, 'store': 3, 'grocery': 3, 'slavery': 2, 'ok': 1, 'better': 1, 'imaginary': 1, 'pinned': 1, 'reposted': 1, 'sidebar': 1, 'frequently': 1} \n",
      "\n",
      "diablo4\n",
      "{'minion': 9, 'dp': 4, 'get': 1, 'skill': 1, 'item': 1, 'work': 2, 'coded': 1, 'game': 1, 'contribution': 2, 'every': 1, 'speculation': 1, 'increase': 1, 'damage': 1, 'file': 1, 'mobile': 1} \n",
      "\n",
      "explainlikeimfive\n",
      "{'cell': 1, 'gene': 3, 'fusion': 3, 'kinase': 1, 'tyrosine': 1, 'fgfr': 1, 'fgfr2': 1, 'wrong': 1, 'basic': 1, 'name': 1, 'would': 1, 'event': 1} \n",
      "\n",
      "facepalm\n",
      "{'amy': 1, 'post': 1, 'modmail': 1, 'subreddit': 1, 'joke': 1, 'sweden': 1, 'asia': 1, 'pure': 1, 'viking': 1, 'replacement': 1, 'loving': 1, 'nah': 1, 'west': 1, 'people': 1} \n",
      "\n",
      "funny\n",
      "{'dog': 16, 'know': 4, 'anything': 1, 'make': 1, 'guess': 1, 'critic': 1, 'funny': 1, 'everyone': 1, 'look': 1, 'social': 1, 'creature': 1, 'reflective': 1, 'comic': 1, 'done': 1, 'homework': 1, 'one': 1, 'version': 1, 'like': 2, 'precursor': 1, 'alleged': 1, 'criticism': 1, 'artist': 1, 'good': 1} \n",
      "\n",
      "gaming\n",
      "{'game': 31, 'dont': 1, 'gravity': 4, 'stuff': 1, 'fall': 2, 'law': 2, 'marion': 1, 'console': 1, 'mayor': 1, 'racist': 1, 'hate': 1, 'pc': 1, 'catsareassholes': 1} \n",
      "\n",
      "interestingasfuck\n",
      "{'nato': 4, 'russia': 12, 'would': 1, 'much': 2, 'also': 1, 'play': 2, 'significantly': 1, 'aid': 1, 'harder': 1, 'pretty': 1, 'well': 1, 'sing': 1, 'playing': 3, 'type': 2, 'lot': 1, 'talented': 1, 'music': 3, 'blind': 1, 'luckily': 1, 'accordion': 1, 'mexican': 1, 'fun': 1, 'traditional': 1} \n",
      "\n",
      "leagueoflegends\n",
      "{'game': 5, 'winrate': 3, 'maybe': 1, 'master': 2, 'player': 1, 'one': 1, 'queue': 1, 'tooltip': 1, 'ranked': 1, 'mmr': 2, 'tier': 1, 'restriction': 1, 'gg': 1, 'month': 1, 'last': 1, 'xdx': 1, 'show': 1, 'think': 1, 'riot': 1, 'api': 2, 'every': 1, 'try': 1, 'track': 1, 'season': 1, 'someone': 1, 'made': 1, 'spreadsheet': 1, 'us': 1, 'find': 1, 'google': 1} \n",
      "\n",
      "mildlyinfuriating\n",
      "{'need': 1, 'rest': 1, 'info': 1, 'provide': 2, 'house': 1, 'number': 1, 'probably': 1, 'refusing': 1, 'iphones': 1, 'stolen': 1, 'lol': 1, 'right': 1} \n",
      "\n",
      "movies\n",
      "{'empire': 1, 'planet': 1, 'asap': 1, 'thank': 1, 'never': 1, 'check': 1, 'seen': 1, 'one': 1, 'read': 1, 'opinion': 2, 'wrong': 1, 'seeing': 1, 'downvoted': 1, 'whole': 1, 'series': 1, 'alright': 1, 'mean': 1, 'love': 1, 'lol': 1, 'case': 1, 'definitely': 1, 'need': 1, 'watch': 1, 'movie': 1} \n",
      "\n",
      "pcmasterrace\n",
      "{'ea': 10, 'see': 1, 'totally': 1, 'overclocked': 1, 'latency': 1, '99ms': 1, 'sleep': 1, 'mode': 1} \n",
      "\n",
      "pics\n",
      "{'uranus': 1, 'toy': 2, 'sweet': 1, 'big': 1, 'thing': 2, 'universal': 1, 'seem': 1, 'ignore': 1, 'play': 1, 'kid': 1, 'content': 1, 'came': 1, 'box': 2, 'got': 1, 'present': 1, 'someone': 1, 'tell': 1, 'bulletproof': 1, 'get': 1, 'lol': 1, 'huge': 1, 'ok': 1, 'wow': 1, 'vibe': 1, 'silent': 1, 'hill': 1, 'hello': 1, 'darkness': 1, 'old': 1, 'friend': 1} \n",
      "\n",
      "therewasanattempt\n",
      "{'trump': 2, 'ever': 1, 'every': 1, 'fixing': 1, 'thing': 1, 'playing': 1, 'yet': 1, 'victim': 1, 'stop': 2, 'steal': 1, 'karma': 1, 'instant': 1, 'fatso': 1, 'tumble': 1, 'honestly': 2, 'thread': 1, 'gotten': 1, 'annoying': 1, 'point': 1, 'political': 1, 'like': 1, 'making': 1} \n",
      "\n",
      "videos\n",
      "{'piece': 1, 'guy': 1, 'good': 1, 'commercial': 1, 'lot': 1, 'voice': 1, 'though': 1, 'dubbed': 1, 'thing': 1, 'improved': 1, 'would': 1, 'simple': 1, 'actually': 1, 'internet': 1, 'year': 1, 'seen': 1, 'golden': 1, 'era': 1, 'age': 1, 'classic': 1} \n",
      "\n",
      "worldnews\n",
      "{'pipe': 3, 'plan': 3, 'u': 1, 'without': 1, 'blowing': 1, 'russia': 1, 'yes': 1, 'shut': 1, 'also': 1, 'considering': 1, 'done': 1, 'contractor': 1, 'alien': 1, 'explosive': 1, 'charge': 1, 'high': 1, 'one': 1, 'shaped': 1, 'could': 1, 'submarine': 1, 'loaded': 1, 'underwater': 1, 'must': 1, 'drone': 1, 'night': 1} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for subreddit in subredditNames:\n",
    "    print(subreddit)\n",
    "    with open('Reddit_Comments/' + subreddit + '.txt') as f:\n",
    "        buffer = {}\n",
    "        k = 31\n",
    "        for line in f:\n",
    "            tokens = line.split()\n",
    "            random.shuffle(tokens)\n",
    "            for token in tokens:\n",
    "                token, isCommonWord = CommonWord(token)\n",
    "                if isCommonWord: continue\n",
    "                MisraGries(token, buffer, k)\n",
    "            \n",
    "    print(buffer, '\\n')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
